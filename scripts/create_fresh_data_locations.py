"""
CORRECT approach: Use all exclusions, but only trust areas with fresh data
"""
import geopandas as gpd
import pandas as pd
from pathlib import Path
import sys
sys.path.append('.')
from src import config

def create_correct_fresh_locations():
    """
    Correct approach:
    1. Use ALL existing scored locations (with full exclusions)
    2. Filter to only locations in areas that had fresh data updates
    """
    
    print("="*80)
    print("ğŸ†• CREATING FRESH DATA LOCATIONS (CORRECT METHOD)")
    print("="*80)
    
    processed = Path(config.DATA_PROCESSED)
    alkis_path = Path(config.DATA_RAW) / 'ALKIS'
    
    # Load all scored locations (these already have full exclusions)
    print("\nğŸ“‚ Loading all scored locations (with full exclusions)...")
    all_locations = gpd.read_file(processed / 'scored_locations_all.geojson')
    print(f"   âœ… Total locations: {len(all_locations):,}")
    
    # Load buildings with date info
    print("\nğŸ¢ Loading buildings with freshness data...")
    buildings = gpd.read_file(alkis_path / 'gebaeudeBauwerke.shp')
    
    if 'aktualit' not in buildings.columns:
        print("   âš ï¸  No date column - cannot determine freshness")
        return
    
    # Identify areas with FRESH updates (2020+)
    fresh_buildings = buildings[buildings['aktualit'] >= '2020-01-01'].copy()
    print(f"   Fresh buildings: {len(fresh_buildings):,} out of {len(buildings):,}")
    
    # Create "fresh zones" - buffer around fresh buildings
    print("\nğŸ—ºï¸  Creating fresh data zones...")
    fresh_buildings['geometry'] = fresh_buildings.buffer(50)  # 50m radius = "fresh zone"
    fresh_zones = fresh_buildings.dissolve().reset_index(drop=True)
    
    print(f"   âœ… Created fresh zones around {len(fresh_buildings):,} updated buildings")
    
    # Load land use to get fresh road zones
    print("\nğŸ›£ï¸  Adding fresh road zones...")
    land_use = gpd.read_file(alkis_path / 'nutzung.shp')
    
    if 'aktualit' in land_use.columns:
        fresh_roads = land_use[
            (land_use['aktualit'] >= '2020-01-01') & 
            (land_use['nutzart'] == 'Strassenverkehr')
        ].copy()
        
        if len(fresh_roads) > 0:
            fresh_roads['geometry'] = fresh_roads.buffer(50)
            fresh_road_zones = fresh_roads.dissolve().reset_index(drop=True)
            
            # Combine zones by concatenating and dissolving
            all_fresh_zones = pd.concat([fresh_zones, fresh_road_zones], ignore_index=True)
            fresh_zones = all_fresh_zones.dissolve().reset_index(drop=True)
            
            print(f"   âœ… Added {len(fresh_roads):,} fresh road zones")
    
    # Filter locations to only those in fresh zones
    print("\nğŸ” Filtering locations to fresh zones only...")
    print("   This keeps locations where data is verified current...")
    
    locations_in_fresh_zones = gpd.sjoin(
        all_locations,
        fresh_zones,
        predicate='within',
        how='inner'
    )
    
    # Remove duplicates from spatial join
    locations_in_fresh_zones = locations_in_fresh_zones[
        ~locations_in_fresh_zones.index.duplicated(keep='first')
    ]
    
    # Keep only original columns
    original_cols = all_locations.columns.tolist()
    fresh_verified = all_locations.loc[locations_in_fresh_zones.index].copy()
    
    print(f"   âœ… Kept {len(fresh_verified):,} locations in verified-fresh zones")
    print(f"   âŒ Removed {len(all_locations) - len(fresh_verified):,} locations in stale zones")
    
    # Re-rank
    fresh_verified = fresh_verified.sort_values('final_score', ascending=False).reset_index(drop=True)
    fresh_verified['rank'] = range(1, len(fresh_verified) + 1)
    fresh_verified['data_quality'] = 'VERIFIED FRESH 2020+'
    
    # Save
    output = processed / 'scored_locations_fresh.geojson'
    fresh_verified.to_file(output, driver='GeoJSON')
    
    print(f"\nğŸ’¾ Saved: {output}")
    
    # Statistics
    print("\n" + "="*80)
    print("ğŸ“Š FRESH DATA SUMMARY (CORRECT METHOD)")
    print("="*80)
    print(f"   Original locations: {len(all_locations):,}")
    print(f"   Fresh zones created: {len(fresh_buildings):,} buildings + roads")
    print(f"   âœ… Verified fresh locations: {len(fresh_verified):,}")
    print(f"   âŒ Removed (stale data): {len(all_locations) - len(fresh_verified):,}")
    print(f"   Percentage verified fresh: {len(fresh_verified)/len(all_locations)*100:.1f}%")
    
    print(f"\nğŸ† Top score: {fresh_verified['final_score'].max():.2f}")
    print(f"   Average score: {fresh_verified['final_score'].mean():.2f}")
    
    print("\nâœ… These locations:")
    print("   â€¢ Use FULL exclusions (all buildings, roads, etc.)")
    print("   â€¢ Are in areas with 2020+ data updates")
    print("   â€¢ Are more reliable for field verification")
    
    # Now enhance and export in one go
    print("\n" + "="*80)
    print("âœ¨ ENHANCING WITH FULL DETAILS...")
    print("="*80)
    
    fresh_enhanced = enhance_and_export(fresh_verified)
    
    print("\n" + "="*80)
    print("âœ… COMPLETE!")
    print("="*80)
    print("\nNext step:")
    print("   python scripts/find_nearest_fresh_locations.py")
    
    return fresh_enhanced

def enhance_and_export(fresh_locations):
    """Enhance with details and export to web format"""
    
    from pathlib import Path
    
    alkis_path = Path(config.DATA_RAW) / 'ALKIS'
    
    # Load land use for social impact
    print("\nğŸ“‚ Loading land use data...")
    land_use = gpd.read_file(alkis_path / 'nutzung.shp')
    if land_use.crs != config.CRS:
        land_use = land_use.to_crs(config.CRS)
    
    # Get proven species
    print("\nğŸŒ³ Adding tree recommendations...")
    trees_path = Path(config.DATA_RAW) / 'Baumkataster'
    tree_files = list(trees_path.glob('*.shp'))
    
    proven_species = ['AhornblÃ¤ttrige Platane', 'Winterlinde `Greenspire`']
    
    def recommend_species(heat_score):
        if heat_score > 80:
            return f"{' or '.join(proven_species)} (proven in Heilbronn, heat-tolerant)"
        else:
            return "Spitz-Ahorn or Robinie (proven in Heilbronn)"
    
    fresh_locations['recommended_species'] = fresh_locations['heat_score'].apply(recommend_species)
    
    # Cooling estimates
    print("â„ï¸  Adding cooling estimates...")
    def estimate_cooling(heat_score):
        if heat_score > 80:
            return "-2.5Â°C in 20m radius"
        elif heat_score > 60:
            return "-2.0Â°C in 15m radius"
        else:
            return "-1.5Â°C in 15m radius"
    
    fresh_locations['cooling_estimate'] = fresh_locations['heat_score'].apply(estimate_cooling)
    
    # Location types
    print("ğŸ“ Determining location types...")
    def get_location_type(point):
        try:
            nearby = land_use[land_use.distance(point) < 20]
            if len(nearby) > 0:
                nutzart = nearby.iloc[0]['nutzart']
                type_map = {
                    'Sport Freizeit Und Erholungsflaeche': 'Recreation Area',
                    'Wohnbauflaeche': 'Residential Green Strip',
                    'Strassenverkehr': 'Street Side'
                }
                return type_map.get(nutzart, 'Green Space')
        except:
            pass
        return "Green Space"
    
    fresh_locations['location_type'] = fresh_locations.geometry.apply(get_location_type)
    
    # Social impact
    print("ğŸ‘¥ Estimating social impact...")
    def estimate_schools(point):
        try:
            nearby = land_use[land_use.distance(point) < 200]
            education = nearby[nearby['nutzart'].isin(['Sport Freizeit Und Erholungsflaeche'])]
            count = len(education) // 2
            if count == 0:
                return "No schools nearby"
            elif count == 1:
                return "~1 school/recreation nearby"
            else:
                return f"~{count} schools/recreation nearby"
        except:
            return "Unknown"
    
    def estimate_residents(point):
        try:
            nearby = land_use[land_use.distance(point) < 100]
            residential = nearby[nearby['nutzart'] == 'Wohnbauflaeche']
            area_hectares = residential.geometry.area.sum() / 10000
            
            if area_hectares < 0.1:
                return "Low density area"
            elif area_hectares < 0.5:
                return "~50-100 residents nearby"
            elif area_hectares < 1.0:
                return "~100-200 residents nearby"
            else:
                estimated = int(area_hectares * 50)
                return f"~{estimated} residents nearby"
        except:
            return "Unknown"
    
    fresh_locations['schools_nearby'] = fresh_locations.geometry.apply(estimate_schools)
    fresh_locations['residents_nearby'] = fresh_locations.geometry.apply(estimate_residents)
    
    # Postal codes
    print("ğŸ“® Assigning postal codes...")
    def assign_postal(row):
        x, y = row.geometry.x, row.geometry.y
        
        if 514500 <= x <= 515500 and 5442500 <= y <= 5443500:
            return '74072', 'Innenstadt'
        elif 515000 <= x <= 516000 and 5443000 <= y <= 5444000:
            return '74074', 'BÃ¶ckingen'
        elif 515500 <= x <= 516500 and 5442500 <= y <= 5443500:
            return '74076', 'Sontheim'
        elif 516000 <= x <= 517000 and 5443000 <= y <= 5444000:
            return '74078', 'Neckargartach'
        elif 514500 <= x <= 515500 and 5443000 <= y <= 5444000:
            return '74080', 'Frankenbach'
        else:
            return 'Unknown', 'Heilbronn'
    
    postal_data = fresh_locations.apply(assign_postal, axis=1)
    fresh_locations['postal_code'] = [p[0] for p in postal_data]
    fresh_locations['area_name'] = [p[1] for p in postal_data]
    
    # Export to web with WGS84
    print("\nğŸŒ Exporting to web format...")
    fresh_locations['utm_x'] = fresh_locations.geometry.x
    fresh_locations['utm_y'] = fresh_locations.geometry.y
    
    fresh_wgs = fresh_locations.to_crs('EPSG:4326')
    fresh_wgs['latitude'] = fresh_wgs.geometry.y
    fresh_wgs['longitude'] = fresh_wgs.geometry.x
    
    # Copy enhanced fields
    for col in ['location_type', 'recommended_species', 'cooling_estimate', 
                'schools_nearby', 'residents_nearby', 'postal_code', 'area_name',
                'utm_x', 'utm_y', 'data_quality']:
        if col in fresh_locations.columns:
            fresh_wgs[col] = fresh_locations[col].values
    
    web_output = Path('web/data/scored_locations_fresh.geojson')
    fresh_wgs.to_file(web_output, driver='GeoJSON')
    print(f"   âœ… Saved web version: {web_output}")
    
    # Also save enhanced version
    enhanced_output = Path(config.DATA_PROCESSED) / 'scored_locations_fresh_enhanced.geojson'
    fresh_locations.to_file(enhanced_output, driver='GeoJSON')
    print(f"   âœ… Saved enhanced: {enhanced_output}")
    
    return fresh_wgs

if __name__ == "__main__":
    fresh_verified = create_correct_fresh_locations()